![Cabe√ßalho README](cabecalho.jpg)
# ü§ñ New Tracking - Intent AI

> New Tracking - Intent AI √© um microsservi√ßo especializado em traduzir linguagem natural para filtros estruturados. Constru√≠do com Python, FastAPI e LangChain, este sistema atua como o "c√©rebro da interpreta√ß√£o" para a plataforma New Tracking. Ele recebe perguntas de usu√°rios em portugu√™s, as normaliza e converte em um objeto JSON preciso, que √© ent√£o consumido pelo NT API backend para consultar uma procedure no banco de dados (SP_TK_NOTAS_AI_HOM). Com uma arquitetura de duas cadeias de IA, o servi√ßo lida com sin√¥nimos, ambiguidades e l√≥gicas de data complexas, permitindo uma intera√ß√£o conversacional poderosa com os dados log√≠sticos.

# üóÇÔ∏è √çndice
- [ü§ñ New Tracking - Intent AI](#-new-tracking---intent-ai)
- [üóÇÔ∏è √çndice](#Ô∏è-√≠ndice)
- [üõ†Ô∏è Tecnologias Usadas](#Ô∏è-tecnologias-usadas)
  - [**Geral**](#geral)
  - [**Interface de Teste e Demonstra√ß√£o (Streamlit)**](#interface-de-teste-e-demonstra√ß√£o-streamlit)
- [üå≥ Estrutura do Projeto](#-estrutura-do-projeto)
- [üîÑ Updates](#-updates)
  - [Nota sobre Chain of Thought (CoT) - Desativado](#nota-sobre-chain-of-thought-cot---desativado)
  - [Pr√≥ximas Implementa√ß√µes](#pr√≥ximas-implementa√ß√µes)
- [üß† Funcionamento](#-funcionamento)
  - [`app/main.py`](#appmainpy)
  - [`app/chains/master_chain.py`](#appchainsmaster_chainpy)
  - [`app/prompts/filter_prompts.py`](#apppromptsfilter_promptspy)
- [Outros M√≥dulos e Ferramentas de Suporte](#outros-m√≥dulos-e-ferramentas-de-suporte)
- [Endpoints](#endpoints)
  - [**1. Endpoint de Produ√ß√£o**](#1-endpoint-de-produ√ß√£o)
    - [**Endpoint:** `POST /parse-query`](#endpoint-post-parse-query)
    - [**Endpoint:** `POST /debug-query`](#endpoint-post-debug-query)
- [üíæ Componente de Banco de Dados](#-componente-de-banco-de-dados)
  - [Stored Procedure: `SP_TK_NOTAS_AI_HOM`](#stored-procedure-sp_tk_notas_ai_hom)
- [üöÄ Instala√ß√£o e Configura√ß√£o Local](#-instala√ß√£o-e-configura√ß√£o-local)
  - [Pr√©-requisitos](#pr√©-requisitos)
  - [Passos de Instala√ß√£o](#passos-de-instala√ß√£o)
  - [Executando a Aplica√ß√£o](#executando-a-aplica√ß√£o)
  - [Ferramentas de Teste e Desenvolvimento](#ferramentas-de-teste-e-desenvolvimento)
- [ü§ù Contato](#-contato)
  - [D√∫vidas, Bugs ou Sugest√µes?](#d√∫vidas-bugs-ou-sugest√µes)
  - [Vamos nos Conectar!](#vamos-nos-conectar)

---

# üõ†Ô∏è Tecnologias Usadas

## **Geral**
- [Python](https://www.python.org/) (**3.12**)
- [FastAPI](https://fastapi.tiangolo.com/)
- [LangChain](https://www.langchain.com/)
- [Pydantic](https://docs.pydantic.dev/latest/)
- [Git](https://git-scm.com/)
- [Modelo LLM - llama-3.1-8b-instant (GROQ)](https://groq.com/)

---

## **Interface de Teste e Demonstra√ß√£o (Streamlit)**

> [!IMPORTANT]
> Este projeto √© um microsservi√ßo de backend, projetado para ser consumido por outra API. Como tal, n√£o inclui uma interface de frontend para o usu√°rio final.

Para fins de desenvolvimento, depura√ß√£o e demonstra√ß√£o, o reposit√≥rio cont√©m uma interface de teste interativa (`test_ui.py`) desenvolvida com **Streamlit**. Esta ferramenta √© essencial para entender o comportamento da IA e permite ao desenvolvedor:

-   **Testar Queries Individuais:** Enviar perguntas em linguagem natural de forma r√°pida, sem a necessidade de usar um cliente de API como o Postman.
-   **Visualizar o Fluxo de IA:** Observar em tempo real a transforma√ß√£o dos dados em cada etapa da cadeia:
    1.  A query original do usu√°rio.
    2.  A vers√£o normalizada pela cadeia `Enhancer`.
    3.  O objeto JSON final extra√≠do pela cadeia `Parser`.
-   **Depurar e Validar:** Validar instantaneamente o resultado das altera√ß√µes nos prompts, tornando o processo de "prompt engineering" muito mais eficiente.

> [!NOTE]
> Esta interface √© uma ferramenta exclusiva para desenvolvimento e n√£o faz parte do servi√ßo principal (`main.py`) exposto pelo Uvicorn/FastAPI.

---

# üå≥ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ üìÅ app
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ chains
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç master_chain.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ core
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç llm.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç filter_prompts.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç main.py
‚îú‚îÄ‚îÄ üìÅ scripts
‚îÇ   ‚îú‚îÄ‚îÄ üêç debug_runner.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç test_ui.py
‚îú‚îÄ‚îÄ üìÅ sql
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ SCRIPT_TESTE_AI_HOM.sql
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ SP_DOC.txt
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ SP_TK_NOTAS_AI_HOM.sql
‚îú‚îÄ‚îÄ üìÅ tests_cases
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ testes.txt
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ testes_pontuais.txt
‚îú‚îÄ‚îÄ üìÅ venvntia
‚îú‚îÄ‚îÄ üîí .env
‚îú‚îÄ‚îÄ üîí .env.example
‚îú‚îÄ‚îÄ üìù README.md
‚îî‚îÄ‚îÄ üìÑ requirements.txt
```


# üîÑ Updates

> [!NOTE]
> Vers√£o 1

| Vers√£o | Data       | Mudan√ßas principais               |
|--------|------------|-----------------------------------|
| 1.0    | 22/10/2025 | MVP funcional


## Nota sobre Chain of Thought (CoT) - Desativado 

Durante o desenvolvimento e otimiza√ß√£o da precis√£o da IA (especialmente na Cadeia de Parsing), a t√©cnica de **Chain of Thought (CoT)** foi implementada e testada.

**O que √© CoT?**

Chain of Thought √© uma t√©cnica de engenharia de prompts onde instru√≠mos o Modelo de Linguagem (LLM) a "pensar passo a passo" antes de fornecer a resposta final. Em vez de pedir diretamente o JSON, o prompt pedia ao LLM para primeiro:
1.  Analisar o texto da consulta.
2.  Listar as entidades extra√≠das.
3.  Verificar as regras de neg√≥cio aplic√°veis.
4.  *S√≥ ent√£o* gerar o "JSON FINAL".

**Motiva√ß√£o para Usar (Benef√≠cios):**

A principal motiva√ß√£o foi **aumentar a precis√£o da extra√ß√£o em consultas complexas**. For√ßar o LLM a articular seu racioc√≠nio intermedi√°rio demonstrou melhorar significativamente a ader√™ncia √†s regras de neg√≥cio complexas, como:
* A preced√™ncia do `StatusAnaliseData` sobre o `TipoData` 
* A correta aplica√ß√£o de regras de coexist√™ncia entre `SituacaoNF` e `StatusAnaliseData`.
* A redu√ß√£o geral de erros onde o LLM poderia "esquecer" um filtro ao tentar formatar o JSON diretamente.

**Como poderia ser Implementado:**

1.  **Prompt (`filter_prompts.py`):** Adicionamos a se√ß√£o "Pense passo a passo..." ao final do `JSON_PARSER_PROMPT`.
    ```python
    # Exemplo do bloco CoT adicionado ao prompt:
    """
    Pense passo a passo antes de gerar o JSON final:
    1.  **An√°lise do Texto:** (...)
    2.  **Extra√ß√£o de Entidades:** (...)
    3.  **Verifica√ß√£o de Regras:** (...)

    JSON FINAL:
    """
    ```
2.  **Orquestra√ß√£o (`master_chain.py`):** Como a sa√≠da do LLM agora continha o "pensamento" + "JSON FINAL:", foi necess√°rio adicionar um passo extra na `json_parser_chain` usando `RunnableLambda` e uma fun√ß√£o auxiliar (`_extract_json_from_output`) para isolar apenas o bloco JSON antes de pass√°-lo ao `OutputFixingParser`.

**Motivo da Desativa√ß√£o:**

Apesar da melhoria na precis√£o, o CoT introduziu um **custo computacional significativamente maior** por chamada √† API do LLM (Groq, usando `llama-3.1-8b-instant` no *free tier*):
* **Lat√™ncia Aumentada:** O tempo de resposta por query aumentou consideravelmente, pois o LLM precisava gerar mais texto (o racioc√≠nio).
* **Problemas com Rate Limiting:** A API da Groq (no n√≠vel gratuito) possui limites de taxa agressivos (aproximadamente 1 chamada complexa/minuto). O CoT tornava as chamadas "caras", ativando o *throttling* (fila de espera) da API e causando timeouts no nosso script de teste (`debug_runner.py`), mesmo com timeouts de cliente aumentados (120s).

**Decis√£o Atual:**

Para garantir a **estabilidade dos testes**, e manter uma **performance aceit√°vel** dentro das limita√ß√µes do *free tier* da Groq, o Chain of Thought foi **desativado**. A precis√£o resultante (sem CoT, mas com prompts e exemplos refinados) foi considerada **muito boa (~97-100%)** e aceit√°vel para o contexto atual da aplica√ß√£o (uso interno). A estrat√©gia de rodar testes em lotes com pausas longas (`debug_runner.py`) provou ser eficaz para evitar novos banimentos.

**Considera√ß√µes Futuras:**

* Se a aplica√ß√£o migrar para um plano pago da API LLM com limites de taxa mais altos.
* Se testes futuros revelarem uma queda inaceit√°vel na precis√£o para casos de uso cr√≠ticos.
* Nesses cen√°rios, a **reativa√ß√£o do CoT** pode ser reconsiderada como uma forma de maximizar a robustez da interpreta√ß√£o.

---
## Pr√≥ximas Implementa√ß√µes
- [ ] Monitorar a frequ√™ncia de erros 400 (JSON nulo) em produ√ß√£o para avaliar a necessidade futura de um Gatekeeper Prompt.
- [ ] Expandir o roteiro de testes com mais casos de borda e combina√ß√µes complexas.
---

# üß† Funcionamento

Nesta se√ß√£o, apresentamos uma vis√£o detalhada de como cada parte do New Tracking - Intent AI opera. Aqui voc√™ encontrar√° uma explica√ß√£o clara de como os m√≥dulos interagem entre si, como os dados fluem da pergunta do usu√°rio at√© a gera√ß√£o do JSON final, e como a intelig√™ncia artificial √© utilizada para normalizar e extrair informa√ß√µes complexas.

O objetivo √© fornecer ao leitor uma compreens√£o completa do funcionamento interno do sistema, permitindo n√£o apenas integr√°-lo, mas tamb√©m entender, manter e expandir seu c√≥digo com facilidade.

> [!TIP]
> **Explore o c√≥digo-fonte!** Cada arquivo de c√≥digo mencionado abaixo foi documentado com um cabe√ßalho descritivo que detalha sua arquitetura, o fluxo de dados (entradas e sa√≠das) e a responsabilidade de cada fun√ß√£o. √â um excelente complemento a esta documenta√ß√£o de alto n√≠vel.

---

## [`app/main.py`](./app/main.py)

> Este arquivo √© respons√°vel por configurar e expor os endpoints da API.

1. **Inicializa√ß√£o:** Carrega as vari√°veis de ambiente e, atrav√©s dos eventos de ciclo de vida (startup/shutdown), gerencia o carregamento e o encerramento da aplica√ß√£o.

2. **Logging:** Implementa um sistema de log robusto que escreve para o console e para um arquivo com rota√ß√£o (logs/nt_ai_service.log), garantindo a observabilidade do servi√ßo.

3. **Carregamento Otimizado:** Invoca a cria√ß√£o das cadeias de IA uma √∫nica vez durante o evento de startup, uma otimiza√ß√£o de performance crucial que evita recarregar os modelos a cada requisi√ß√£o.

4. **Endpoints Ass√≠ncronos:** Define os endpoints /parse-query (produ√ß√£o) e /debug-query (testes) de forma ass√≠ncrona (async def), permitindo que o servidor lide com m√∫ltiplas requisi√ß√µes concorrentes de forma eficiente.

---

## [`app/chains/master_chain.py`](./app/chains/master_chain.py)

> Este m√≥dulo √© o cora√ß√£o da l√≥gica de IA, respons√°vel por montar e conectar as diferentes etapas do processo de interpreta√ß√£o.

**Arquitetura e Princ√≠pio de Design:**

A arquitetura segue o princ√≠pio de "Separa√ß√£o de Responsabilidades", operando como uma linha de montagem com as seguintes etapas:

1. **C√°lculo de Datas em Tempo de Execu√ß√£o:**

    - **Responsabilidade:** Garantir que a IA sempre trabalhe com o contexto de tempo correto.

    - **A√ß√£o:** A cada requisi√ß√£o, a fun√ß√£o _get_current_dates calcula dinamicamente todos os per√≠odos relevantes (hoje, ontem, semana de calend√°rio, m√™s de calend√°rio, etc.) e os injeta no fluxo de dados.

2. **O Tradutor (query_enhancer_chain):**

    **- Responsabilidade:** Normalizar a pergunta do usu√°rio de forma segura.

    **- A√ß√£o:** Recebe a pergunta bruta e a traduz para os termos de neg√≥cio, expandindo abrevia√ß√µes (ex: "nf" -> "nota fiscal") sem alterar a inten√ß√£o original.

3. **O Especialista em Extra√ß√£o (json_parser_chain):**

    - **Responsabilidade:** Converter a pergunta j√° normalizada em um objeto JSON estruturado.

    - **A√ß√£o:** Recebe a pergunta clara e os dados de tempo e, com base em regras e exemplos, extrai todas as entidades (status, locais, ordena√ß√£o) para o formato JSON final.

4. **Resili√™ncia com OutputFixingParser:**

    - **esponsabilidade:** Garantir que a sa√≠da seja sempre um JSON sintaticamente v√°lido.

    - **A√ß√£o:** Se o LLM gerar um JSON com erro de sintaxe, esta ferramenta automaticamente solicita ao LLM que corrija seu pr√≥prio erro antes de retornar o resultado


## [`app/prompts/filter_prompts.py`](.app/prompts/filter_prompts.py)

> Este arquivo centraliza todas as instru√ß√µes que definem o comportamento da IA. √â aqui que a "personalidade" e as "habilidades" do sistema s√£o moldadas.

**Componentes Principais:**

1. **QUERY_ENHANCER_PROMPT (O Tradutor):**

    - Cont√©m as "Regras de Ouro" que pro√≠bem a IA de adicionar ou remover informa√ß√µes, garantindo a preserva√ß√£o da inten√ß√£o do usu√°rio.

    - Define um dicion√°rio de mapeamento de sin√¥nimos (ex: "rodando", "viajando" -> "em tr√¢nsito") e abrevia√ß√µes.

2. **JSON_PARSER_PROMPT (O Especialista em Extra√ß√£o):**

    - Define o "schema" do JSON de sa√≠da, listando todas as entidades que a IA deve extrair.

    - Cont√©m se√ß√µes de regras detalhadas para lidar com ambiguidades (entregue com data vs. entregue como status), precis√£o de datas (per√≠odos relativos vs. de calend√°rio) e hierarquias (prioridade de filtros).

    - Utiliza uma extensa lista de exemplos (Few-Shot Learning) para ensinar √† IA o comportamento esperado em cen√°rios complexos, como filtros combinados com ordena√ß√£o.


# Outros M√≥dulos e Ferramentas de Suporte

> Al√©m dos arquivos centrais que definem a l√≥gica da IA, o projeto conta com outros m√≥dulos de suporte e ferramentas de desenvolvimento. Cada um desses arquivos possui sua pr√≥pria documenta√ß√£o interna detalhada para explicar seu funcionamento.

- `app/core/llm.py:` Este arquivo atua como uma "f√°brica" que centraliza a cria√ß√£o e configura√ß√£o do modelo de linguagem (ChatGroq). Isso facilita a manuten√ß√£o e a troca do modelo em um √∫nico local.

- `scripts/debug_runner.py:` Uma ferramenta de linha de comando para executar o roteiro de testes (ex: testes_completos.txt) de forma automatizada, exibindo os resultados de cada query diretamente no terminal. √â essencial para a valida√ß√£o em lote.

- `scripts/test_ui.py:` Lan√ßa uma interface web local com Streamlit, ideal para testes individuais, prototipa√ß√£o r√°pida de novas regras de prompt e demonstra√ß√µes visuais do fluxo da IA.

- `sql/:` Esta pasta organiza todo o c√≥digo SQL relevante para o projeto, incluindo a procedure principal SP_TK_NOTAS_AI_HOM e os scripts usados para valida√ß√£o no banco de dados.

- `tests_case/:` Armazena os arquivos .txt que cont√™m as frases em linguagem natural usadas como entrada para os testes de integra√ß√£o, servindo como a "fonte da verdade" para validar o comportamento da IA.


# Endpoints

> Esta se√ß√£o detalha os endpoints que sua API exp√µe, o que √© crucial para a equipe que ir√° consumir seu microsservi√ßo.

## **1. Endpoint de Produ√ß√£o**

### **Endpoint:** `POST /parse-query`

**Descri√ß√£o:** Recebe uma query em linguagem natural e retorna apenas o objeto JSON final com os filtros extra√≠dos. Este √© o endpoint que deve ser consumido pela aplica√ß√£o principal.
  
- **Request Body:**
  ```json
  {
    "query": "notas entregues hoje para o cliente BEXX"
  }
- **Success Response (200 OK)**
    ```
    {
    "NF":NULL
    "DE":"2025-10-17"
    "ATE":"2025-10-17"
    "TipoData":"2"
    "Cliente":"BEXX"
    "Transportadora":NULL
    "UFDestino":NULL
    "CidadeDestino":NULL
    "Operacao":NULL
    "SituacaoNF":NULL
    "StatusAnaliseData":NULL
    "CNPJRaizTransp":NULL
    "SortColumn":NULL
    "SortDirection":NULL
    }
    ```
### **Endpoint:** `POST /debug-query`

**Descri√ß√£o:** Endpoint para desenvolvimento e diagn√≥stico. Retorna um objeto JSON contendo os resultados de cada etapa da cadeia de IA.
  
- **Request Body:**
  ```json
  {
    "query": "notas entregues hoje para o cliente BEXX"
  }
- **Success Response (200 OK)**
    ```
    {
    "query": "notas entregues hoje para o cliente BEXX",
    "dates": {
        "today": "2025-10-17",
        "yesterday": "2025-10-16",
        "last_week_start": "2025-10-10",
        "week_start": "2025-10-13",
        "week_end": "2025-10-19",
        "month_start": "2025-10-01",
        "month_end": "2025-10-31",
        "semester_start": "2025-07-01",
        "semester_end": "2025-12-31"
    },
    "enhanced_query": "Quais notas fiscais foram entregues hoje para o cliente BEXX?",
    "parsed_json": {
        "NF": null,
        "DE": "2025-10-17",
        "ATE": "2025-10-17",
        "TipoData": "2",
        "Cliente": "BEXX",
        "Transportadora": null,
        "UFDestino": null,
        "CidadeDestino": null,
        "Operacao": null,
        "SituacaoNF": null,
        "StatusAnaliseData": null,
        "CNPJRaizTransp": null,
        "SortColumn": null,
        "SortDirection": null
    }
    }
    ```

# üíæ Componente de Banco de Dados

## Stored Procedure: `SP_TK_NOTAS_AI_HOM`

Representa o est√°gio final do fluxo de dados iniciado pela consulta do usu√°rio. Esta Stored Procedure, localizada no diret√≥rio [`/sql`](./sql/), √© a **consumidora direta** do objeto JSON gerado pelo microsservi√ßo Intent AI.

**Responsabilidades Principais:**

1.  **Receber Filtros:** Aceita todos os par√¢metros extra√≠dos pela IA (datas, `TipoData`, `Cliente`, `Transportadora`, `UFDestino`, `CidadeDestino`, `Operacao`, `SituacaoNF`, `StatusAnaliseData`, `CNPJRaizTransp`, `SortColumn`, `SortDirection`) como par√¢metros de entrada.
2.  **Consulta Din√¢mica:** Constr√≥i e executa uma consulta SQL din√¢mica sobre a view principal (`VW_NOTAS`), aplicando apenas os filtros que foram fornecidos (n√£o nulos) no JSON.
3.  **Otimiza√ß√£o:** Utiliza uma tabela tempor√°ria (`#FilteredData`) para aplicar os filtros iniciais de forma eficiente antes de realizar JOINs mais complexos para enriquecimento de dados.
4.  **L√≥gica de Neg√≥cio e Permiss√µes:** Inclui l√≥gicas espec√≠ficas do New Tracking, como o tratamento de datas padr√£o ('1900-01-01'), formata√ß√£o de sa√≠da e, crucialmente, a aplica√ß√£o de regras de permiss√£o de acesso baseadas no `@IdUsuario`.
5.  **Ordena√ß√£o:** Implementa a ordena√ß√£o din√¢mica dos resultados com base nos par√¢metros `@SortColumn` e `@SortDirection`.

> [!TIP]
> **Documenta√ß√£o Detalhada da Procedure:**
> A Stored Procedure `SP_TK_NOTAS_AI_HOM` possui uma l√≥gica SQL complexa e otimiza√ß√µes espec√≠ficas. Para uma an√°lise aprofundada de seus par√¢metros, blocos l√≥gicos (valida√ß√£o, pr√©-filtragem, joins, permiss√µes, ordena√ß√£o), depend√™ncias (como `VW_NOTAS`) e exemplos de execu√ß√£o direta no banco, consulte o arquivo de documenta√ß√£o dedicado:
>
> **[`./sql/PROCEDURE_SP_TK_NOTAS_AI_HOM_DOCS.md`](./sql/PROCEDURE_SP_TK_NOTAS_AI_HOM_DOCS.md)**

---
# üöÄ Instala√ß√£o e Configura√ß√£o Local

> Siga os passos detalhados abaixo para configurar e executar o microsservi√ßo `nt-ai` em seu ambiente de desenvolvimento local, desde os pr√©-requisitos at√© a execu√ß√£o dos testes.

## Pr√©-requisitos

Antes de come√ßar, garanta que seu sistema possui as ferramentas essenciais para clonar, configurar e executar o projeto:

* [Python](https://www.python.org/downloads/) (Vers√£o **3.12**)
* [Git](https://git-scm.com/downloads/)
* Opcional, mas **altamente recomendado:** [uv](https://github.com/astral-sh/uv) (um gerenciador de pacotes e ambientes virtuais Python extremamente r√°pido).

> [!TIP]
> **O que √© `uv`?**
> `uv` √© uma ferramenta moderna desenvolvida pela Astral (a mesma equipe por tr√°s do Ruff linter) que visa substituir `pip`, `venv`, `pip-tools` e outros, oferecendo uma experi√™ncia unificada e significativamente mais r√°pida para gerenciamento de depend√™ncias e ambientes virtuais em Python. Os comandos neste guia mostrar√£o a op√ß√£o com `uv` (preferencial) e a alternativa padr√£o com `pip`/`venv`.

* Um editor de c√≥digo (como [VS Code](https://code.visualstudio.com/))
* Acesso √† internet para baixar depend√™ncias e interagir com a API da Groq.

## Passos de Instala√ß√£o

> Siga esta sequ√™ncia para baixar o c√≥digo, configurar o ambiente isolado e instalar todas as bibliotecas necess√°rias.

1.  **Clonar o Reposit√≥rio:**
    Abra seu terminal ou Git Bash e clone o projeto:
    ```bash
    git clone https://github.com/Marocosz/nt-ai
    cd nt-ai
    ```

2.  **Criar e Ativar o Ambiente Virtual:**
    √â crucial usar um ambiente virtual para isolar as depend√™ncias. Navegue at√© a pasta raiz do projeto (`nt-ai`) no terminal.

    * **Usando `uv` (Recomendado):**
        ```bash
        # Criar o ambiente virtual (muito r√°pido)
        uv venv venvntai

        # Ativar o ambiente virtual
        # No Windows (PowerShell):
        .\venvntai\Scripts\Activate.ps1
        # No Windows (Git Bash):
        source venvntai/Scripts/activate
        # No macOS/Linux:
        # source venvntai/bin/activate
        ```

    * **Alternativa com `python -m venv` (Padr√£o):**
        ```bash
        # Criar o ambiente virtual
        python -m venv venvntai

        # Ativar o ambiente virtual (mesmos comandos acima)
        # Windows (PowerShell): .\venvntai\Scripts\Activate.ps1
        # Windows (Git Bash): source venvntai/Scripts/activate
        # macOS/Linux: source venvntai/bin/activate
        ```
    Voc√™ saber√° que o ambiente est√° ativo pois o nome `(venvntai)` aparecer√° no in√≠cio do prompt do seu terminal.

3.  **Instalar as Depend√™ncias:**
    Com o ambiente virtual ativado, instale as bibliotecas listadas no `requirements.txt`.

    * **Usando `uv` (Recomendado, muito mais r√°pido):**
        ```bash
        uv pip install -r requirements.txt
        ```

    * **Alternativa com `pip` (Padr√£o):**
        ```bash
        pip install -r requirements.txt
        ```

4.  **Configurar Vari√°veis de Ambiente:**
    Este projeto precisa de uma chave de API para o servi√ßo LLM da Groq.
    * Crie um arquivo chamado `.env` na **raiz do projeto** (`nt-ai/`).
    * Abra o arquivo `.env` e adicione a linha abaixo, inserindo sua chave real obtida no [Console da Groq](https://console.groq.com/keys):
        ```env
        GROQ_API_KEY=<SUA_CHAVE_API_GROQ>
        ```
    * **Importante:** Adicione `.env` ao seu arquivo `.gitignore` para evitar commitar acidentalmente sua chave secreta.

## Executando a Aplica√ß√£o

> Com o ambiente configurado, veja como iniciar o servidor da API e verificar se ele est√° funcionando corretamente.

1.  **Iniciar o Servidor FastAPI:**
    No terminal, com o ambiente virtual ativado e na pasta raiz do projeto, execute:
    ```bash
    uvicorn app.main:app --reload --port 5001
    ```
    * `app.main:app`: Aponta para a inst√¢ncia `app` do FastAPI no arquivo `app/main.py`.
    * `--reload`: Reinicia o servidor automaticamente ao salvar altera√ß√µes no c√≥digo (ideal para desenvolvimento).
    * `--port 5001`: Define a porta de execu√ß√£o (ajuste se necess√°rio).

2.  **Verificar a Aplica√ß√£o:**
    O terminal mostrar√° logs indicando que o servidor est√° rodando em `http://127.0.0.1:5001`.
    * Abra `http://127.0.0.1:5001/docs` no seu navegador para acessar a documenta√ß√£o interativa (Swagger UI) e testar os endpoints diretamente.

## Ferramentas de Teste e Desenvolvimento

> Al√©m do servidor principal, utilize estas ferramentas auxiliares para validar e depurar o comportamento da IA.

1.  **Executor de Testes em Lote (`debug_runner.py`):**
    Roda um conjunto de queries de um arquivo `.txt` (como `testes_mestre.txt`) contra o endpoint `/debug-query`, aplicando pausas para evitar problemas com a API da Groq.
    ```bash
    # Mantenha o servidor FastAPI (uvicorn) rodando em outro terminal
    python scripts/debug_runner.py tests_case/testes_mestre.txt
    ```
    *(Use o nome correto do seu arquivo de testes)*

2.  **Interface de Teste Streamlit (`test_ui.py`):**
    Oferece uma interface web interativa para testes r√°pidos individuais e visualiza√ß√£o do fluxo da IA.
    ```bash
    # Mantenha o servidor FastAPI (uvicorn) rodando em outro terminal
    streamlit run scripts/test_ui.py
    ```
    A interface ser√° aberta automaticamente no seu navegador padr√£o.

---

# ü§ù Contato

## D√∫vidas, Bugs ou Sugest√µes?

Se voc√™ encontrar algum bug, tiver alguma d√∫vida t√©cnica sobre o c√≥digo ou uma sugest√£o de melhoria, a melhor forma de entrar em contato √© **abrindo uma Issue** diretamente no reposit√≥rio do GitHub. Isso ajuda a manter tudo organizado e vis√≠vel para todos.

- **[‚û°Ô∏è Abrir uma Issue no GitHub](https://github.com/Marocosz/nt-ai/issues)**

---

## Vamos nos Conectar!

Adoraria ouvir seu feedback e me conectar com outros desenvolvedores e entusiastas de tecnologia. Voc√™ pode me encontrar nas seguintes plataformas:

- **Desenvolvido por:** `Marcos Rodrigues`
- üíº **LinkedIn:** [`https://www.linkedin.com/in/marcosrodriguesptc`](https://www.linkedin.com/in/marcosrodriguesptc/)
- üêô **GitHub:** [`https://github.com/Marocosz`](https://github.com/Marocosz)
- üìß **Email:** `marcosrodriguesepro@gmail.com`

Sinta-se √† vontade para se conectar!